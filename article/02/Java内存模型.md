
# 并发编程模型的两个关键问题
 * 线程间如何通信？即：线程之间以何种机制来交换信息
 * 线程间如何同步？即：线程以何种机制来控制不同线程间操作发生的相对顺序
  
有两种并发模型可以解决这两个问题：

* 消息传递并发模型
* 共享内存并发模型  

这两种模型之间的区别如下表所示：

        |    | 如何通信 | 如何同步
-------------|--|---
消息传递模型 | 线程之前**没有公共状态**，线程间的通信必须通过消息发送显式通信|发送消息天然同步，因为发送消息总是接受消息之前，因此同步是隐式的。
共享内存模型 | 线程之间共享程序的公共状态，通过**写-读内存中的公共状态**隐式通信|**必须显式指定某段代码需要在线程之间互斥执行**，同步是显式的。



在Java中，使用的是共享内存并发模型。
# Java内存模型的抽象结构
## 运行时内存的划分
先谈一下运行时数据区，下面这张图相信大家一点都不陌生：
![image](https://raw.githubusercontent.com/chenxiao19920206/RedSpiderArticlePhotos/master/java-base/multi-thread/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA.png)

对于每一个线程来说，栈都是私有的，而堆是共有的。也就是说在栈中的变量（局部变量、方法定义参数、异常处理器参数）不会在线程之间共享，也就不会有内存可见性（下文会说到）的问题，也不受内存模型的影响。而在堆中的变量是共享的，本文称为共享变量。


所以，内存可见性是针对的**共享变量**，这里提到的及时性是指：一个线程已经对一个共享变量值做了修改，其他线程在使用这个共享变量的时候，如果这个值是新值，那就被称作“及时地”被其他线程看到。如果是旧值，那么这个共享变量的修改对其他线程是不可见的。

## 既然堆是共享的，为什么在堆中会有内存不可见问题？
这是因为现代计算机为了高效，往往会在高速缓存区中缓存共享变量，因为cpu访问缓存区比访问内存要快得多。
>线程之间的共享变量存在主内存中，每个线程都有一个私有的本地内存，存储了该线程以读、写共享变量的副本。本地内存是Java内存模型的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器等。

Java线程之间的通信由Java内存模型（简称JMM）控制，从抽象的角度来说，JMM定义了线程和主内存之间的抽象关系。JMM的抽象示意图如图所示：

![image](https://raw.githubusercontent.com/chenxiao19920206/RedSpiderArticlePhotos/master/java-base/multi-thread/JMM%E6%8A%BD%E8%B1%A1%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

从图中可以看出：
1. 所有的共享变量都存在主内存中。
2. 每个线程都保存了一份该线程使用到的共享变量的副本。
3. 如果线程A与线程B之间要通信的话，必须经历下面2个步骤：
    1. 线程A将本地内存A中更新过的共享变量刷新到主内存中去。
    2. 线程B到主内存中去读取线程A之前已经更新过的共享变量。

**所以，线程A无法直接访问线程B的工作内存，线程间通信必须经过主内存。**

注意，根据JMM的规定，**线程对共享变量的所有操作都必须在自己的工作内存中进行，不能直接从主内存中读取**。所以线程B并不是直接去主内存中读取共享变量的值，而是现在本地内存B中找到这个共享变量，发现这个共享变量已经被更新了，然后工作内存B去主内存中读取这个共享变量的新值，并拷贝到工作内存B中，最后线程B再读取工作内存B中的新值。

那么怎么知道这个共享变量的被其他线程更新了呢？这就是JMM的功劳了，也是JMM存在的必要性之一。**JMM通过控制主内存与每个线程的本地内存之间的交互，来提供内存可见性保证**。

## JMM与java内存区域划分的区别与联系
上面两小节分别提到了JMM和java运行时内存区域的划分，这两者既有差别又有联系：
* 区别

    两者是不同的概念层次。JMM是抽象的，他是用来描述一组规则，通过这个规则来控制各个变量的访问方式，围绕原子性、有序性、可见性等展开的。而Java运行时内存的划分是具体的，是JVM运行java程序时，必要的内存划分。
* 联系

    都存在私有数据区域和共享数据区域。一般来说，JMM中的主内存属于共享数据区域，他是包含了堆和方法区；同样，JMM中的本地内存属于私有数据区域，包含了程序计数器、本地方法栈、虚拟机栈。

**实际上，他们表达的是同一种含义，这里不做区分。**

下面介绍一下几个重要的概念：
### 原子性
原子性是指一个操作不可中断，即便是在多线程的环境下，一个操作一旦开始，就不会被其他线程影响。比如对于一个静态变量int x，有两个线程分别对x赋值，线程A赋值x=1，线程B赋值x=2,那么无论如何运行，x的值要么是1，要么是2，不可能是其他值，这就是原子性操作。

有人会想，x的值不是1就是2，这个不是很显然吗？这里举一个反例：对于32位系统来说，对于long类型和double类型变量的读写是非原子性的，也就是说，如果同时存在两个线程对数据类型是long或者double的共享变量进行读写是会相互干扰的，因为32位的JVM每次的读写是32位，而long和double类型都是64位；这样会导致线程A在写时，操作完前32位的原子操作后，这时候线程切换，线程B读取这个变量，就有可能读到一个既非原值又不是线程A修改后的值，而是“半个变量”的数值。

不过可以放心，这种情况在现代JVM中，比较少见，基本可以认为对64位的数据类型也是原子操作。

### 重排序
计算机在执行程序时，为了提高性能，编辑器和处理器常常会对指令做重排。

> **为什么指令重排序可以提高性能？**   
    简单地说，每一个指令都会包含多个步骤，每个步骤可能使用不同的硬件。因此，流水线技术产生了，他的原理是指令1还没有执行完，就可以开始执行指令2，而不用等到指令1执行结束之后再执行指令2，这样就大大提高了效率。<br>
    但是，流水线技术最害怕中断，恢复中断的代价是比较大的，所以我们要想尽办法不让流水线中断。那么指令重排就是减少中断的一种技术。   
    我们分析一下下面这个代码的执行情况：
        ```
        a=b+c;
        d=e-f;
        ```
    先装载b、c(注意，可能不是装载b了之后再装载c)，但是在执行add(b,c)的时候，需要等待b、c装载结束才能继续执行，也就是增加了停顿，那么后面的指令也会依次有停顿。为了减少这个停顿，我们可以先装载e和f,然后再去装载add(b,c),这样做对程序（串行）是没有影响的,但却减少了停顿。既然add(b,c)需要停顿，那还不如去做一些有意义的事情。   
    综上所述，指令重排对于提高CPU处理性能十分必要。虽然由此带来了乱序的问题，但是这点牺牲是值得的。

指令重排一般分为以下三种：

#### 编译器优化重排

编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
#### 指令并行重排

现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。
    
#### 内存系统重排

由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。

**指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。**
### 可见性
一个线程对**共享变量**值的修改,能够**及时地**被其他线程看到。

### 有序性
对于单线程的执行代码，我们可以认为是按照顺序依次执行。但是在多线程环境里面，因为有指令重排以及工作内存和主内存的同步延迟，所以一个线程中观察另外一个线程，所有的操作都是无序的。

# 顺序一致性模型
顺序一致性模型是一个**理论参考模型**，内存模型在设计的时候都会以顺序一致性内存模型作为参考。

## 数据竞争与顺序一致性
当程序未正确同步的时候，就可能存在数据竞争。
> 数据竞争：在一个线程中写一个变量，在另一个线程读同一个变量，并且写和读没有通过同步来排序。

如果程序中包含了数据竞争，那么运行的结果往往充满了不确定性。如果一个线程程序能够正确同步，那么就不存在数据竞争。

JMM对于正确同步多线程程序的内存一致性做了以下保证：
> **如果程序是正确同步的，程序的执行将具有顺序一致性。** 即程序的执行结果和该程序在顺序一致性模型中执行的结果相同。

这里的同步包括了volatile、final、synchronized。

## 顺序一致性模型
> 顺序一致性内存模型是一个理想化的理论参考模型，它为程序员提供了极强的内存可见性保证。
> 顺序一致性模型有两大特性：
> 1. 一个线程中的所有操作必须按照程序的顺序来执行。
> 2. 不管程序是否同步，所有线程都只能看到一个单一的操作执行顺序。在顺序一致性模型中，每个操作必须是原子性的且立刻对所有线程可见。

为了理解这两个特性，我们举个例子，假设有两个线程A和B并发执行，线程A有3个操作，他们在程序中的顺序是A1->A2->A3，线程B也有3个操作，B1->B2->B3。

假设正确使用了同步，A线程的3个操作执行后释放锁，B线程获取同一个锁。那么在**顺序一致性模型**中的执行效果如下所示：
```
graph LR
A1-->A2
A2-->A3
A3-->B1
B1-->B2
B2-->B3
```
操作的执行整体上有序，并且两个线程都只能看到这个执行顺序。

假设没有使用同步，那么在**顺序一致性模型**中的执行效果如下所示：
```
graph LR
B1-->A1
A1-->A2
A2-->B2
B2-->A3
A3-->B3
```
操作的执行整体上无序，但是两个线程都只能看到这个执行顺序。之所以可以得到这个保证，是因为顺序一致性模型中的**每个操作必须立即对西任意线程可见**。

**但是JMM没有这样的保证。**
比如，在当前线程把写过的数据缓存在本地内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，这个写操作根本没有被当前线程所执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才对其他线程可见。在这种情况下，当前线程和其他线程看到的执行顺序是不一样的。

## JMM中同步程序的顺序一致性效果
在顺序一致性模型中，所有操作完全按照程序的顺序串行执行。但是JMM中，临界区内（同步中的代码）的代码可以重排序（但不允许临界区内的代码“逃逸”到临界区之外，因为会破坏监视器的语义）。

虽然线程A在临界区做了重排序，但是因为监视器锁的特性，线程B无法观察到线程A在临界区的重排序。这种重排序既提高了执行效率，有没有改变程序的执行结果。

同时，JMM会在退出临界区和进入临界区做特殊的处理，使得在临界区内程序获得与顺序一致性模型相同的内存视图（后面会详细讲）。

> **由此可见，JMM的具体实现方针是：在不改变（正确同步的）程序执行结果的前提下，尽量为编译期和处理器的优化打开方便之门**
## JMM中未同步程序的顺序一致性效果

对于未同步的多线程程序，JMM只提供最小安全性：线程读取到的值，要么是之前某个线程写入的值，要么是默认值，不会无中生有。

为了实现这个安全性，JMM在堆上分配对象时，首先会对内存空间清零，然后才会在上面分配对象（这两个操作是同步的）。在已经清零的内存空间分配对象是，域的默认初始化已经完成。

JMM没有保证未同步程序的执行结果与该程序在顺序一致性中执行结果一致。因为如果要保证执行结果一致，那么JMM需要禁止大量的优化，对程序的执行性能会产生很大的影响。

未同步程序在JMM和顺序一致性内存模型中的执行特性如下差异：
1. 顺序一致性保证单线程内的操作会按程序的顺序执行；JMM不保证单线程内的操作会按程序的顺序执行。（重排序）
2. 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。
3. JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读写操作都具有原子性。

# 参考内容
* 《Java并发编程的艺术》
* 《Java高并发程序设计》

